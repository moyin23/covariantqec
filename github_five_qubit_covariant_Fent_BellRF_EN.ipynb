{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "972e7feb",
   "metadata": {},
   "source": [
    "# Covariant encoding via RF states, based on 5-qubit code\n",
    "- RF states in this code is 'N' copies of Bell state\n",
    "- The performance is measured by 'entanglement error'\n",
    "    1. Note: 'entanglement error = 1-Fent' for qubit covariant channel "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d9ed8",
   "metadata": {},
   "source": [
    "### Note: In this program, we calculate entanglement fidelity\n",
    "- For qubit covariant channel:\n",
    "    1. entanglement error = 1-Fent'\n",
    "    2. worst case error <= 2 * entanglement error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8418a2c9",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Function part\n",
    "    1. Used modules and some matrices\n",
    "    2. Generate random SU(2) matrix\n",
    "    3. From $|U_g / \\sqrt{2} >> ^{\\otimes N} $, get final measurement outcome $U_h$\n",
    "    3. ' $|U_g / \\sqrt{2} >> ^{\\otimes N} $ pass through IID p-depolarizing, get final measurement outcome $U_h$\n",
    "    4. About coding -- functions related to 5-qubit code\n",
    "    5. About coding -- get the state after Ug encoding关于code部分 -- 得到经过encoding state\n",
    "    6. About coding -- after noise and Uh decoding, calculate the entanglement error\n",
    "- Numerical experiment part\n",
    "    1. erasure noise\n",
    "    2. completely depolarizing noise (one fifth RF states pass through noise)\n",
    "    3. completely dephasing noise (one fifth RF states pass through noise)\n",
    "    4. IID p-depolarizing noise (every RF state pass through p-depolarizing noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0811cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-qubit code\n",
    "# Input: 1 logical qubit，1 ancilla qubit，Output: 4 measure qubits, 5 code qubits, 1 ancilla qubit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cb411f",
   "metadata": {},
   "source": [
    "## Function Part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412710de",
   "metadata": {},
   "source": [
    "### 1. Used modules and some matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt  # For plot\n",
    "from scipy.optimize import curve_fit  # For fitting\n",
    "from scipy.stats import unitary_group  # Generate random unitary matrix\n",
    "\n",
    "\n",
    "# get measure outcome via optimization, with the help of \"paddle quantum\"\n",
    "import paddle\n",
    "from paddle_quantum.circuit import UAnsatz  # Create Quantum Circuit\n",
    "from paddle_quantum.state import vec, vec_random  # Generate Quantum state, (vector)\n",
    "from paddle_quantum.state import density_op, density_op_random, completely_mixed_computational  # Generate Quantum state, (matrix)\n",
    "from paddle_quantum.utils import dagger  # Take dagger for paddle.tensor\n",
    "from paddle import matmul, trace  # Calculate inner product and trace for paddle.tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168ca9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some matrices\n",
    "\n",
    "# Bell state -- np ket\n",
    "bell_state = np.array([[1,0,0,1]]) / (2**0.5)\n",
    "bell_state = bell_state.conj().T\n",
    "\n",
    "# Pauli matrices\n",
    "pauli_x = np.array([[0.0, 1.0], [1.0, 0.0]])\n",
    "pauli_y = np.array([[0.0, -1.0j], [1.0j, 0.0]])\n",
    "pauli_z = np.array([[1.0, 0.0], [0.0, -1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140c9960",
   "metadata": {},
   "source": [
    "### 2. Generate random SU(2) matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bab8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate random SU(2) martrix: -- U2_random_Euler_mod()\n",
    "\n",
    "def Rz(alpha):\n",
    "    # output U：np.array -- rotation around Z axis with angle alpha\n",
    "    U = np.array([[0.+0.j, 0.+0.j],[0.+0.j, 0.+0.j]])\n",
    "    U[0][0] = np.e ** (-1j * alpha/2)\n",
    "    U[1][1] = np.e ** (1j * alpha/2)\n",
    "    \n",
    "    return U\n",
    "\n",
    "def Ry(alpha):\n",
    "    # output U：np.array -- rotation around Y axis with angle alpha\n",
    "    U = np.array([[0.+0.j, 0.+0.j],[0.+0.j, 0.+0.j]])\n",
    "    U[0][0] = np.cos(alpha/2)\n",
    "    U[0][1] = -np.sin(alpha/2)\n",
    "    U[1][0] = np.sin(alpha/2)\n",
    "    U[1][1] = np.cos(alpha/2)\n",
    "    \n",
    "    return U\n",
    "\n",
    "def U2_Euler(alpha, beta, gamma):\n",
    "    # output U：np.array -- rotation with Euler angle representation\n",
    "    # U(alpha, beta, gamma) = Z(gamma) @ Y(beta) @ Z(alpha)\n",
    "    # Note: alpha, gamma \\in [0,2pi], beta \\in [0,pi]\n",
    "    U = Rz(gamma) @ Ry(beta) @ Rz(alpha)\n",
    "    return U\n",
    "\n",
    "\n",
    "\n",
    "def random_sinx(a, b):\n",
    "    # Gerenrate distribution sin(x)dx, x \\in [a,b]\n",
    "        # Note：sin(x) should be > 0 for x \\in [a,b]\n",
    "    # Generate random (x,y), x \\in [a,b], y \\in [0, maxy]\n",
    "        # for (xi, yi), if 0<yi<f(xi), output xi\n",
    "    ymax = 1  # sin(x) always smaller than 1\n",
    "    while 1:\n",
    "        x = random.uniform(a, b)\n",
    "        y = random.uniform(0, 1)\n",
    "        if y < np.sin(x):\n",
    "            break\n",
    "    return x,y\n",
    "\n",
    "def U2_random_Euler_mod():\n",
    "    # output U：np.array -- rotation with Euler angle representation\n",
    "    # beta in distribution sin(beta)d(beta), alpha, gamma are uniform\n",
    "    alpha = random.uniform(0, 2*np.pi)\n",
    "    beta, anc = random_sinx(0, np.pi)\n",
    "    gamma = random.uniform(0, 2*np.pi)\n",
    "    U = Rz(gamma) @ Ry(beta) @ Rz(alpha)\n",
    "    \n",
    "    return U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b417d5",
   "metadata": {},
   "source": [
    "### 3. From $|U_g / \\sqrt{2} >> ^{\\otimes N} $, get final measurement outcome $U_h$\n",
    "- This part deals with RF states pass through erasure noise, or completely depolarizing noise, orcompletely dephasing noise\n",
    "- For completely depolarizing noise, a majority vote algorithm will be first used to get rid of n noisy outcomes (here we suppose that the number of how many RF states pass through noise is known)\n",
    "- The final Uh from N measure outcomes {Uh1, ... UhN} is derived via paddle quantum, by optimizing loss function: L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh|Uhi>> |^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ccef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. From Ug get final Uh\n",
    "# 3.1 Generate a list of Uhi from distribution p(h|g) = 1/4 * | <<Ug|Uh>> |^2\n",
    "# 3.2 For depolarizing noise, get rid of n noisy outcomes\n",
    "# 3.3 For dephasing noise, get rid of n noisy outcomes\n",
    "\n",
    "# 3.1 Generate a list of Uhi from distribution p(h|g) = 1/4 * | <<Ug|Uh>> |^2\n",
    "def random_fromg_geth(Ug):\n",
    "    # Input: Ug: np.matrix, distribution\n",
    "    # Output: Uh:np.matrix: distribution -- p(h|g) = 1/4 * | <<Ug|Uh>> |^2\n",
    "    pgh_max = 1  # p(h|g) always smaller than 1\n",
    "    while 1:\n",
    "        Uh = U2_random_Euler_mod()\n",
    "        pgh = random.uniform(0, pgh_max)\n",
    "        fgh = 1/4 * ((Ug.conj().T @ Uh).trace()) * ((Ug.conj().T @ Uh).trace().conj())  # 1/4 * | <<Ug|Uh>> |^2\n",
    "        fgh = np.real(fgh)\n",
    "        if pgh < fgh:\n",
    "            break\n",
    "    return Uh\n",
    "\n",
    "def measoutcome_gN(Ug, N):\n",
    "    # Input: Ug: np.matrix, distribution\n",
    "    # Output: a list {Uh1, ... UhN}:np.matrix: distribution -- p(h|g) = 1/4 * | <<Ug|Uh>> |^2\n",
    "    Uh_list = []\n",
    "    for i in range(N):\n",
    "        Uh = random_fromg_geth(Ug)\n",
    "        Uh_list.append(Uh)\n",
    "    \n",
    "    return Uh_list\n",
    "\n",
    "# 3.2 For depolarizing noise, get rid of n noisy outcomes\n",
    "def getrid_dep(Uh_list, N, n):\n",
    "    # Input: Uh_list: A list contain N+n elements: np.matrix\n",
    "        # N follows distribution p(h|g) = 1/4 * | <<Ug|Uh>> |^2, n are randomly created as comes from maximally mixed state\n",
    "    # Output: Uh_list_final -- get rid of n noisy outcomes: np.matrix\n",
    "        # Method: For every Uhi, calculate Sum_j 1/4 * <<Uhi|Uhj>><<Uhj|Uhi>>, eliminate the smallest n elements.\n",
    "    H_hlist = np.zeros([4,4])\n",
    "    for i in range(N+n):\n",
    "        # H_hlist = Sum_j |Uhj>><<Uhj| -- 1/4 can be ignored\n",
    "        Uhi = Uh_list[i]\n",
    "        H_hlist = H_hlist + np.kron(Uhi, np.eye(2)) @ bell_state @ bell_state.conj().T @ np.kron(Uhi, np.eye(2)).conj().T\n",
    "    # Calculate  <<Uhi | H_hlist | Uhi>> for each Uhi\n",
    "    fh_list = []\n",
    "    for i in range(N+n):\n",
    "        Uhi = Uh_list[i]\n",
    "        fhi = bell_state.conj().T @ np.kron(Uhi, np.eye(2)).conj().T @ H_hlist @ np.kron(Uhi, np.eye(2)) @ bell_state\n",
    "        fhi = np.real(fhi)\n",
    "        fh_list.append(fhi)\n",
    "    # Calculate the smallest n terms -- using function: find_max(given_list)\n",
    "    Uh_list_final = Uh_list.copy()\n",
    "    for i in range(n):\n",
    "        loc_min = find_min(fh_list)\n",
    "        del fh_list[loc_min]\n",
    "        del Uh_list_final[loc_min]\n",
    "    \n",
    "    return Uh_list_final\n",
    "\n",
    "def find_min(given_list):\n",
    "    # Input: A list\n",
    "    # Output: the location of the smallest number\n",
    "    location = 0\n",
    "    num = given_list[0]\n",
    "    for i in range(len(given_list)):\n",
    "        if num > given_list[i]:\n",
    "            num = given_list[i]\n",
    "            location = i\n",
    "    \n",
    "    return location\n",
    "\n",
    "# 3.3 For dephasing noise, get rid of n noisy outcomes\n",
    "def random_fromg_geth_dephasing(Ug):\n",
    "    # Input: Ug: np.matrix, distribution\n",
    "    # Output: Uh:np.matrix: distribution -- p(h|g) = 1/4 * <<Uh| (|Ug>> <<Ug|/2 + |ZUg>> <<UgZ|/2 ) |Uh>> \n",
    "    pgh_max = 1  # p(h|g) always smaller than 1\n",
    "    state_g_final1 = np.kron(Ug, np.eye(2)) @ bell_state @ (np.kron(Ug, np.eye(2)) @ bell_state).conj().T\n",
    "    state_g_final2 = np.kron(pauli_z, np.eye(2)) @ np.kron(Ug, np.eye(2)) @ bell_state @ (np.kron(pauli_z, np.eye(2)) @ np.kron(Ug, np.eye(2)) @ bell_state).conj().T\n",
    "    state_g_final = state_g_final1 + state_g_final2\n",
    "    while 1:\n",
    "        Uh = U2_random_Euler_mod()\n",
    "        pgh = random.uniform(0, pgh_max)\n",
    "        fgh = 1/4 * (np.kron(Uh, np.eye(2)) @ bell_state).conj().T @ state_g_final @ (np.kron(Uh, np.eye(2)) @ bell_state)  # p(h|g) = 1/4 * <<Uh| (|Ug>> <<Ug|/2 + |ZUg>> <<UgZ|/2 ) |Uh>> \n",
    "        fgh = np.real(fgh)\n",
    "        if pgh < fgh:\n",
    "            break\n",
    "    return Uh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c4ff7",
   "metadata": {},
   "source": [
    "- From N measure outcomes {Uh1, ... UhN} get the maximum likelihood Uh -- in Euler angle representation\n",
    "- Optimize the 3 Euler angles\n",
    "- Loss function: L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh(alphah, betah, gammah) | Uhi>> |^2\n",
    "- Two main functions:\n",
    "    1. For erasure noise, the probability get Uhi: p(hi|g) = 1/4 * | <<Ug|Uhi>> |^2\n",
    "        - From_g_get_hath(Ug, N)\n",
    "    2. For non-erasure noise, first need to use majority vote as given above to get rid of the noisy Uhi\n",
    "        - From_g_get_hath_noise(Ug, N, n, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f103d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From N measure outcomes {Uh1, ... UhN} get the maximum likelihood Uh -- in Euler angle representation\n",
    "# Optimization is done via \"Paddle Quantum\"\n",
    "\n",
    "# paddle quantun ancilla functions\n",
    "# Generate the parameterized quantum network\n",
    "def circuit_fromhNtoh(N_cir, DEPTH_cir, alpha, beta, gamma):\n",
    "    # The parameterized quantum network has N_cir=2 qubits, and Depth:EPTH_cir = 3\n",
    "    cir = UAnsatz(N_cir)\n",
    "    # The first qubit goes through Uh = Rz(gamma) Ry(beta) Rz(alpha)\n",
    "    cir.rz(alpha[0], 0)\n",
    "    cir.ry(beta[0], 0)\n",
    "    cir.rz(gamma[0], 0)\n",
    "\n",
    "    return cir\n",
    "\n",
    "# Forward part: calculate the loss function: L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh|Uhi>> |^2\n",
    "class Opt_fromhNtoh(paddle.nn.Layer):\n",
    "    # 1. def __init__(…)；\n",
    "    def __init__(self, N_cir, DEPTH_cir, H_cir, ini_cir, dtype='float64'):\n",
    "        super(Opt_fromhNtoh, self).__init__()\n",
    "        # Initial variables\n",
    "        self.N_cir = N_cir\n",
    "        self.DEPTH_cir = DEPTH_cir\n",
    "        self.alpha = self.create_parameter(shape=[1],  # 角度参数alpha\n",
    "                default_initializer=paddle.nn.initializer.Uniform(low=0., high=2*np.pi), \n",
    "                dtype=dtype, is_bias=False)\n",
    "        self.beta = self.create_parameter(shape=[1],  # 角度参数beta\n",
    "                default_initializer=paddle.nn.initializer.Uniform(low=0., high=np.pi), \n",
    "                dtype=dtype, is_bias=False)\n",
    "        self.gamma = self.create_parameter(shape=[1],  # 角度参数gamma\n",
    "                default_initializer=paddle.nn.initializer.Uniform(low=0., high=2*np.pi), \n",
    "                dtype=dtype, is_bias=False)\n",
    "        self.H = paddle.to_tensor(H_cir, dtype='complex128')\n",
    "        self.ini_cir = paddle.to_tensor(ini_cir, dtype='complex128')\n",
    "\n",
    "    def forward(self):\n",
    "        # The PQC\n",
    "        cir = circuit_fromhNtoh(self.N_cir, self.DEPTH_cir, self.alpha, self.beta, self.gamma)\n",
    "        # The output state\n",
    "        state_final = cir.run_density_matrix(self.ini_cir)\n",
    "        # Calculate the loss function\n",
    "        loss = trace(matmul(self.H, state_final))  # L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh|Uhi>> |^2\n",
    "        loss = paddle.real(loss)\n",
    "\n",
    "        return loss, cir\n",
    "\n",
    "\n",
    "\n",
    "# Main function 1: For erasure noise, the probability get Uhi: p(hi|g) = 1/4 * | <<Ug|Uhi>> |^2\n",
    "def From_g_get_hath(Ug, N):\n",
    "    # Given Ug, get the output Uh, N is the RF states number\n",
    "    # 1. From Ug, get Uhi list: N elements\n",
    "    # 2. Use paddle quantum to get final Uh\n",
    "    # Input：Ug (np.matrix)， N：N RF states\n",
    "    # Output：Uh (np.matrix)\n",
    "    \n",
    "    # 0. Parameters in optimization\n",
    "    ITR = 125       # The number for iteration\n",
    "    LR = 0.3        # Learning rate\n",
    "    SEED = 100        # random seed\n",
    "    paddle.seed(SEED)  # seed for paddle quantum\n",
    "    \n",
    "    # 1. From Ug, get Uhi list: N elements\n",
    "    Uhi_list = measoutcome_gN(Ug, N)\n",
    "    \n",
    "    # 2. Use paddle quantum to get final Uh\n",
    "    # 2.1 For loss function: L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh|Uhi>> |^2\n",
    "        # L = Tr[rho_out \\cdot H_cir]\n",
    "        # H_cir：Sum_i=1^N (-) 1/2 |Uhi>><<Uhi| -- in optimization, we do minimization\n",
    "    H_cir = np.zeros([4,4])\n",
    "    for i in range(N):\n",
    "        # Get Sum_i=1^N - 1/2 |Uhi>><<Uhi| -- 1/2 is in bell_state\n",
    "        Uhi = Uhi_list[i]\n",
    "        H_cir = H_cir - np.kron(Uhi, np.eye(2)) @ bell_state @ bell_state.conj().T @ np.kron(Uhi, np.eye(2)).conj().T\n",
    "    # 2.2 Forward network\n",
    "    ini_cir = bell_state @ bell_state.conj().T\n",
    "    N_cir = 2\n",
    "    DEPTH_cir = 3\n",
    "    \n",
    "    # 2.3 Backward optimization\n",
    "    loss_list = []\n",
    "    alphah_list = []\n",
    "    betah_list = []\n",
    "    gammah_list = []\n",
    "    myLayer = Opt_fromhNtoh(N_cir, DEPTH_cir, H_cir, ini_cir)\n",
    "    # The optimizer is chosen to be Adam\n",
    "    opt = paddle.optimizer.Adam(learning_rate = LR, parameters = myLayer.parameters())    \n",
    "    # Itertation\n",
    "    for itr in range(ITR):\n",
    "        # Calculate the loss function in each iteration\n",
    "        loss = myLayer()[0]\n",
    "        # Modify the parameters\n",
    "        loss.backward()\n",
    "        opt.minimize(loss)\n",
    "        opt.clear_grad()\n",
    "        # recode the learning curves\n",
    "        loss_list.append(loss.numpy()[0])\n",
    "        alphah_list.append(myLayer.parameters()[0][0].numpy())\n",
    "        betah_list.append(myLayer.parameters()[1][0].numpy())\n",
    "        gammah_list.append(myLayer.parameters()[2][0].numpy())\n",
    "    \n",
    "    # Get the final Uh\n",
    "    Uh = U2_Euler(alphah_list[-1][0], betah_list[-1][0], gammah_list[-1][0])\n",
    "    \n",
    "    return Uh\n",
    "\n",
    "\n",
    "\n",
    "# Main function 2: For non-erasure noise, first need to use majority vote as given above to get rid of the noisy Uhi\n",
    "def From_g_get_hath_noise(Ug, N, n, noise):\n",
    "    # Given Ug, get the output Uh, \n",
    "    # N is the RF states number, n: noisy RF states number, noisy: noisy models\n",
    "        # noise = 1: completely depolarizing\n",
    "        # noise = 2:completely dephasing\n",
    "    # 1. From Ug, get Uhi list: N elements\n",
    "    # 2. Use paddle quantum to get final Uh\n",
    "    # Output：Uh (np.matrix)\n",
    "\n",
    "    \n",
    "    # 0. Parameters in optimization\n",
    "    ITR = 125       # The number for iteration\n",
    "    LR = 0.3        # Learning rate\n",
    "    SEED = 100        # random seed\n",
    "    paddle.seed(SEED)  # seed for paddle quantum\n",
    "    \n",
    "    # 1. From Ug, get Uhi list: N elements\n",
    "    Uhi_list_withnoise = measoutcome_gN(Ug, N)\n",
    "    # For completely depolarizing noise\n",
    "    if noise == 1:\n",
    "        # Add n random Uhi to the list\n",
    "        for i_noise in range(n):\n",
    "            Uhi_list_withnoise.append(U2_random_Euler_mod())\n",
    "    # For completely dephasing noise\n",
    "    if noise == 2:\n",
    "        # Add n Uhi to the list in distribution p(h|g) = 1/4 * <<Uh| (|Ug>> <<Ug|/2 + |ZUg>> <<UgZ|/2 ) |Uh>> \n",
    "        for i_noise in range(n):\n",
    "            Uhi_list_withnoise.append(random_fromg_geth_dephasing(Ug))\n",
    "    # Get rid of the n noisy outcomes\n",
    "    Uhi_list = getrid_dep(Uhi_list_withnoise, N, n)\n",
    "    \n",
    "    # 2. Use paddle quantum to get final Uh\n",
    "    # 2.1 For loss function: L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh|Uhi>> |^2\n",
    "        # L = Tr[rho_out \\cdot H_cir]\n",
    "        # H_cir：Sum_i=1^N (-) 1/2 |Uhi>><<Uhi| -- in optimization, we do minimization\n",
    "    H_cir = np.zeros([4,4])\n",
    "    for i in range(N):\n",
    "        # Get Sum_i=1^N - 1/2 |Uhi>><<Uhi| -- 1/2 is in bell_state\n",
    "        Uhi = Uhi_list[i]\n",
    "        H_cir = H_cir - np.kron(Uhi, np.eye(2)) @ bell_state @ bell_state.conj().T @ np.kron(Uhi, np.eye(2)).conj().T\n",
    "    # 2.2 Forward network\n",
    "    ini_cir = bell_state @ bell_state.conj().T\n",
    "    N_cir = 2\n",
    "    DEPTH_cir = 3\n",
    "    \n",
    "    # 2.3 Backward optimization\n",
    "    loss_list = []\n",
    "    alphah_list = []\n",
    "    betah_list = []\n",
    "    gammah_list = []\n",
    "    myLayer = Opt_fromhNtoh(N_cir, DEPTH_cir, H_cir, ini_cir)\n",
    "    # The optimizer is chosen to be Adam\n",
    "    opt = paddle.optimizer.Adam(learning_rate = LR, parameters = myLayer.parameters())    \n",
    "\n",
    "    # Itertation\n",
    "    for itr in range(ITR):\n",
    "        # Calculate the loss function in each iteration\n",
    "        loss = myLayer()[0]\n",
    "        # Modify the parameters\n",
    "        loss.backward()\n",
    "        opt.minimize(loss)\n",
    "        opt.clear_grad()\n",
    "        # recode the learning curves\n",
    "        loss_list.append(loss.numpy()[0])\n",
    "        alphah_list.append(myLayer.parameters()[0][0].numpy())\n",
    "        betah_list.append(myLayer.parameters()[1][0].numpy())\n",
    "        gammah_list.append(myLayer.parameters()[2][0].numpy())\n",
    "    # Get the final Uh\n",
    "    Uh = U2_Euler(alphah_list[-1][0], betah_list[-1][0], gammah_list[-1][0])\n",
    "    \n",
    "    return Uh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82a4fd8",
   "metadata": {},
   "source": [
    "### 3' $|U_g / \\sqrt{2} >> ^{\\otimes N} $ pass through IID p-depolarizing, get final measurement outcome $U_h$\n",
    "- This part deals with RF states pass through IID p-depolarizing noise\n",
    "- From Ug give final Uh\n",
    "- From N measure outcomes {Uh1, ... UhN} get the maximum likelihood Uh -- in Euler angle representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbe80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IID noisy model (strong noise model), with probability (1-p) RF  doesn't change, with probability p becomes max mixed\n",
    "\n",
    "def random_fromg_geth_strong(Ug, p):\n",
    "    # Input: Ug: np.matrix, distribution\n",
    "    # Output: Uh:np.matrix: distribution -- p(h|g) = (1-p) * 1/4 * | <<Ug|Uh>> |^2  +  p / 4\n",
    "    pgh_max = 1  # p(h|g) always smaller than 1\n",
    "    while 1:\n",
    "        Uh = U2_random_Euler_mod()\n",
    "        pgh = random.uniform(0, pgh_max)\n",
    "        fgh = (1-p) * 1/4 * ((Ug.conj().T @ Uh).trace()) * ((Ug.conj().T @ Uh).trace().conj()) + p/4  # (1-p) * 1/4 * | <<Ug|Uh>> |^2  +  p / 4\n",
    "        fgh = np.real(fgh)\n",
    "        if pgh < fgh:\n",
    "            break\n",
    "    return Uh\n",
    "\n",
    "def measoutcome_gN_strong(Ug, N, p):\n",
    "    # Input: Ug: np.matrix, distribution\n",
    "    # Output: a list {Uh1, ... UhN}:np.matrix: distribution -- p(h|g) = (1-p) * 1/4 * | <<Ug|Uh>> |^2  +  p / 4\n",
    "    Uh_list = []\n",
    "    for i in range(N):\n",
    "        Uh = random_fromg_geth_strong(Ug, p)\n",
    "        Uh_list.append(Uh)\n",
    "    \n",
    "    return Uh_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c498d",
   "metadata": {},
   "source": [
    "- From N measure outcomes {Uh1, ... UhN} get the maximum likelihood Uh -- in Euler angle representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def From_g_get_hath_noise_strong(Ug, N, p):\n",
    "    # IID noisy model (strong noise model), with probability (1-p) RF  doesn't change, with probability p becomes max mixed\n",
    "    # Given Ug, get the output Uh, N is the RF states number\n",
    "    # 1. From Ug, get Uhi list: N elements\n",
    "    # 2. Use paddle quantum to get final Uh\n",
    "    # Input：Ug (np.matrix)， N：N RF states, p\n",
    "    # Output：Uh (np.matrix)\n",
    "    \n",
    "    # 0. Parameters in optimization\n",
    "    ITR = 155       # The number for iteration\n",
    "    LR = 0.3        # Learning rate\n",
    "    SEED = 100        # random seed\n",
    "    paddle.seed(SEED)  # seed for paddle quantum\n",
    "    \n",
    "    # 1. From Ug, get Uhi list: N elements\n",
    "    Uhi_list_withnoise = measoutcome_gN_strong(Ug, N, p)\n",
    "    \n",
    "    # 2. Use paddle quantum to get final Uh\n",
    "    # 2.1 For loss function: L(alphah, betah, gammah) = Sum_i=1^N 1/4 * | <<Uh|Uhi>> |^2\n",
    "        # L = Tr[rho_out \\cdot H_cir]\n",
    "        # H_cir：Sum_i=1^N (-) 1/2 |Uhi>><<Uhi| -- in optimization, we do minimization\n",
    "    H_cir = np.zeros([4,4])\n",
    "    for i in range(N):\n",
    "        # Get Sum_i=1^N - 1/2 |Uhi>><<Uhi| -- 1/2 is in bell_state\n",
    "        Uhi = Uhi_list_withnoise[i]\n",
    "        H_cir = H_cir - np.kron(Uhi, np.eye(2)) @ bell_state @ bell_state.conj().T @ np.kron(Uhi, np.eye(2)).conj().T\n",
    "    # 2.2 Forward network\n",
    "    ini_cir = bell_state @ bell_state.conj().T\n",
    "    N_cir = 2\n",
    "    DEPTH_cir = 3\n",
    "    \n",
    "    # 2.3 Backward optimization\n",
    "    loss_list = []\n",
    "    alphah_list = []\n",
    "    betah_list = []\n",
    "    gammah_list = []\n",
    "    myLayer = Opt_fromhNtoh(N_cir, DEPTH_cir, H_cir, ini_cir)\n",
    "    # The optimizer is chosen to be Adam\n",
    "    opt = paddle.optimizer.Adam(learning_rate = LR, parameters = myLayer.parameters())    \n",
    "\n",
    "    # Itertation\n",
    "    for itr in range(ITR):\n",
    "        # Calculate the loss function in each iteration\n",
    "        loss = myLayer()[0]\n",
    "        # Modify the parameters\n",
    "        loss.backward()\n",
    "        opt.minimize(loss)\n",
    "        opt.clear_grad()\n",
    "        # recode the learning curves\n",
    "        loss_list.append(loss.numpy()[0])\n",
    "        alphah_list.append(myLayer.parameters()[0][0].numpy())\n",
    "        betah_list.append(myLayer.parameters()[1][0].numpy())\n",
    "        gammah_list.append(myLayer.parameters()[2][0].numpy())\n",
    "    # Get the final Uh\n",
    "    Uh = U2_Euler(alphah_list[-1][0], betah_list[-1][0], gammah_list[-1][0])\n",
    "    \n",
    "    return Uh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb95a64",
   "metadata": {},
   "source": [
    "### 4. About coding -- functions related to 5-qubit code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201367ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some related functions for encoding, decoding\n",
    "\n",
    "# Binary to Decimal ---- for encoding\n",
    "def TwoToTen(a_two):\n",
    "    # Input: Binary string:  a_two\n",
    "    # Output: Decimal number: a_ten\n",
    "    a_ten = 0\n",
    "    for i in range(len(a_two)):\n",
    "        new = int(a_two[len(a_two)-i-1])  # Get the last \"i+1\"-th number\n",
    "        a_ten = a_ten + new * (2**i)\n",
    "    \n",
    "    return a_ten\n",
    "\n",
    "# Decimal to Binary ---- for decoding\n",
    "def TenToTwo(a_ten, n):\n",
    "    # Input: Decimal number: a_ten, n: the length of the output string\n",
    "    # Output: Binary string:  a_two\n",
    "    a_two = ''\n",
    "    while a_ten:\n",
    "        new = a_ten % 2\n",
    "        new = str(new)\n",
    "        a_two += new\n",
    "        a_ten = a_ten // 2\n",
    "    if len(a_two) < n:\n",
    "        for i in range(n - len(a_two)):\n",
    "            a_two += '0'\n",
    "    a_two = a_two[::-1]\n",
    "    \n",
    "    return a_two\n",
    "\n",
    "# Get the measure probability and output state for the 5-qubit code\n",
    "# state is in order: 4 measure qubits \\otimes 5 code qubits \\otimes 1 ancilla qubit\n",
    "def MeasFiveQ(final_state, basis):\n",
    "    # Input: final_state: 10-qubit code state after noise (numpy.matrix), basis: wanted measure outcome \n",
    "        # 0 for 0000, 1 for 0001,... 15 for 1111\n",
    "    # Output: The measure probability and the remaining 6-qubit state: 5 code qubits \\otimes 1 ancilla qubit (numpy.matrix)\n",
    "        # pr, meas_prob_basis\n",
    "    meas_prob_basis = np.kron(vec(basis, 4), np.eye(2**6)) @ final_state @ np.kron(vec(basis, 4).conj().T, np.eye(2**6))\n",
    "    pr = np.real(meas_prob_basis.trace())\n",
    "    if pr > 0:  # pr should not be 0\n",
    "        meas_prob_basis = meas_prob_basis / pr  # 归一化\n",
    "    \n",
    "    return pr, meas_prob_basis\n",
    "\n",
    "# Circuit for Stabilizer measure for 5-qubit code (in paddle quantum form)\n",
    "def stabilizer_meas(cir):\n",
    "    # Input: 10-qubit initial circuit\n",
    "    # Four initial H gates on measure qubits\n",
    "    for i in range(4):\n",
    "        cir.h(i)\n",
    "    # 1：XZZXI\n",
    "    cir.cnot([0,4])\n",
    "    cir.cz([0,5])\n",
    "    cir.cz([0,6])\n",
    "    cir.cnot([0,7])\n",
    "    # 2：IXZZX\n",
    "    cir.cnot([1,5])\n",
    "    cir.cz([1,6])\n",
    "    cir.cz([1,7])\n",
    "    cir.cnot([1,8])\n",
    "    # 3：XIXZZ\n",
    "    cir.cnot([2,6])\n",
    "    cir.cz([2,7])\n",
    "    cir.cz([2,8])\n",
    "    cir.cnot([2,4])\n",
    "    # 4：ZXIXZ\n",
    "    cir.cnot([3,7])\n",
    "    cir.cz([3,8])\n",
    "    cir.cz([3,4])\n",
    "    cir.cnot([3,5])\n",
    "    # Four final H gates on measure qubits\n",
    "    for i in range(4):\n",
    "        cir.h(i)\n",
    "        \n",
    "    return None\n",
    "\n",
    "# Do correction in decoding according to measure outcomes\n",
    "def correct_accoring_tomeas(meas_out, outstate):\n",
    "    # Input: meas_out: measure outcome (string)\n",
    "            # outstate (np.matrix), 5 code \\otimes 1 anc\n",
    "    # Output: final_state: state after correction (np.matrix)\n",
    "\n",
    "    if meas_out == '0000':\n",
    "        U_cor = np.eye(2**6)\n",
    "    elif meas_out == '0001':\n",
    "        U_cor = np.kron(pauli_x, np.eye(2**5))\n",
    "    elif meas_out == '1000':\n",
    "        U_cor = np.kron(np.eye(2**1), np.kron(pauli_x, np.eye(2**4)))\n",
    "    elif meas_out == '1100':\n",
    "        U_cor = np.kron(np.eye(2**2), np.kron(pauli_x, np.eye(2**3)))    \n",
    "    elif meas_out == '0110':\n",
    "        U_cor = np.kron(np.eye(2**3), np.kron(pauli_x, np.eye(2**2)))\n",
    "    elif meas_out == '0011':\n",
    "        U_cor = np.kron(np.eye(2**4), np.kron(pauli_x, np.eye(2**1)))\n",
    "    elif meas_out == '1010':\n",
    "        U_cor = np.kron(pauli_z, np.eye(2**5))\n",
    "    elif meas_out == '0101':\n",
    "        U_cor = np.kron(np.eye(2**1), np.kron(pauli_z, np.eye(2**4)))\n",
    "    elif meas_out == '0010':\n",
    "        U_cor = np.kron(np.eye(2**2), np.kron(pauli_z, np.eye(2**3)))\n",
    "    elif meas_out == '1001':\n",
    "        U_cor = np.kron(np.eye(2**3), np.kron(pauli_z, np.eye(2**2)))\n",
    "    elif meas_out == '0100':\n",
    "        U_cor = np.kron(np.eye(2**4), np.kron(pauli_z, np.eye(2**1)))\n",
    "    elif meas_out == '1011':\n",
    "        U_cor = np.kron(pauli_y, np.eye(2**5))\n",
    "    elif meas_out == '1101':\n",
    "        U_cor = np.kron(np.eye(2**1), np.kron(pauli_y, np.eye(2**4)))\n",
    "    elif meas_out == '1110':\n",
    "        U_cor = np.kron(np.eye(2**2), np.kron(pauli_y, np.eye(2**3)))\n",
    "    elif meas_out == '1111':\n",
    "        U_cor = np.kron(np.eye(2**3), np.kron(pauli_y, np.eye(2**2)))\n",
    "    else:  # meas_out == '0111':\n",
    "        U_cor = np.kron(np.eye(2**4), np.kron(pauli_y, np.eye(2**1)))\n",
    "        \n",
    "    # The final state\n",
    "    final_state = U_cor @ outstate @ U_cor.conj().T\n",
    "    \n",
    "    return final_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee20de0",
   "metadata": {},
   "source": [
    "### 5. About coding -- get the state after Ug encoding\n",
    "- 5-qubit code encoding algorithm\n",
    "- The order of the space: 4 meas * 5 code * 1 anc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97973067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some vectors and matrices used in Encoding\n",
    "# 5-qubit Encoding\n",
    "# |0_L> = 1/4*(00000 + 10010 + 01001 + 10100 + 01010 - 11011 - 00110 - 11000 - 11101 - 00011 - 11110 - 01111 - 10001 - 01100 - 10111 + 00101)\n",
    "# |1_L> = 1/4*(11111 + 01101 + 10110 + 01011 + 10101 - 00100 - 11001 - 00111 - 00010 - 11100 - 00001 - 10000 - 01110 - 10011 - 01000 + 11010)\n",
    "    # Note: the expression from wiki has some problems\n",
    "    \n",
    "# Generate |0_L>, |1_L>: code_0, code_1\n",
    "# |0_L>，(np.ket)\n",
    "code_0 = np.zeros([2**5, 1])\n",
    "code_0_list_plus = ['00000', '10010', '01001', '10100', '01010', '00101']\n",
    "code_0_list_minus = ['11011', '00110', '11000', '11101', '00011', '11110', '01111', '10001', '01100', '10111']\n",
    "for i in range(len(code_0_list_plus)):\n",
    "    code_0[TwoToTen(code_0_list_plus[i])] = 1/4\n",
    "for i in range(len(code_0_list_minus)):\n",
    "    code_0[TwoToTen(code_0_list_minus[i])] = -1/4\n",
    "# |0_L><0_L| density matrix\n",
    "code_0_density = code_0 @ code_0.conj().T\n",
    "\n",
    "# |1_L>，(np.ket)\n",
    "code_1 = np.zeros([2**5, 1])\n",
    "code_1_list_plus = ['11111', '01101', '10110', '01011', '10101', '11010']\n",
    "code_1_list_minus = ['00100', '11001', '00111', '00010', '11100', '00001', '10000', '01110', '10011', '01000']\n",
    "for i in range(len(code_1_list_plus)):\n",
    "    code_1[TwoToTen(code_1_list_plus[i])] = 1/4\n",
    "for i in range(len(code_1_list_minus)):\n",
    "    code_1[TwoToTen(code_1_list_minus[i])] = -1/4\n",
    "# |1_L><1_L| density matrix\n",
    "code_1_density = code_1 @ code_1.conj().T\n",
    "    \n",
    "# The Encoding isometry: V_Eori\n",
    "# V_E0 = |0_L><0| + |1_L><1|\n",
    "V_Eori = code_0 @ vec(0,1) + code_1 @ vec(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba6cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the state after encoding:\n",
    "# For covarient encoding: V_Ecov = (Ug)^\\otimes 5 V_E0 Ug^dag\n",
    "# Hilbert space order: 4 meas * 5 code * 1 anc\n",
    "\n",
    "def state_afterencoding(Ug):\n",
    "    # Input: Ug\n",
    "    # Output: input_total (paddle.matrix), final state in \"4 meas * 5 code * 1 anc\"\n",
    "    \n",
    "    # (Ug)^\\otimes 5\n",
    "    Ug5 = Ug\n",
    "    for i in range(4):\n",
    "        Ug5 = np.kron(Ug5, Ug)  # (Ug)^\\otimes 5\n",
    "    # V_Ecov = (Ug)^\\otimes 5 V_E0 Ug^dag\n",
    "    V_Ecov = Ug5 @ V_Eori @ Ug.conj().T\n",
    "    \n",
    "    # Get the state after encoding\n",
    "    # Initial state: 1 logical \\otimes 1 ancilla\n",
    "    logical_ini = bell_state\n",
    "    # After encoding: state：input_code, input_total\n",
    "    input_code = np.kron(V_Ecov, np.eye(2)) @ logical_ini  # code \\otimes anc，(np.ket)\n",
    "    input_code_density = input_code @ input_code.conj().T  # code \\otimes anc，(np.matrix)\n",
    "    input_total = np.kron(vec(0, 4).conj().T, input_code)  # add 4 measure qubits\n",
    "    input_total = input_total * input_total.conj().T  # (np.matrix)\n",
    "    input_total = paddle.to_tensor(input_total, dtype = 'complex128')  # change to paddle density\n",
    "    \n",
    "    return input_total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dad3104",
   "metadata": {},
   "source": [
    "### 6. About coding -- after noise and Uh decoding, calculate the entanglement fidelity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f213f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity_hg(Ug, Uh, input_total, noise):\n",
    "    # Input: Ug, Uh -- np.matrix，\n",
    "            # input_total: state after encoding -- paddle.matrix\n",
    "            # noise model\n",
    "                # noise = 1，a code qubit pass through the completely depolarizing noise\n",
    "                # noise = 2，a code qubit pass through the completely dephasing noise\n",
    "    # Output: fidelityh: Entanglement error with Ug encoding and Uh decoding\n",
    "    \n",
    "    # 1. Get the state after noise -- state_afternoise (np.matrix)\n",
    "    # The input is input_total (paddle.matrix):  4 mea \\otimes 5 code \\otimes 1 anc\n",
    "    # Go through the noise channel\n",
    "    cir_noise = UAnsatz(10)  # This code has 10 qubit -- 4 measure, 5 code, 1 ancilla\n",
    "    if noise == 1:\n",
    "        # a code qubit pass through the completely depolarizing noise, p = 3/4\n",
    "        cir_noise.depolarizing(3/4, 5)\n",
    "    if noise == 2:\n",
    "        # a code qubit pass through the completely dephasing noise, p = 3/4\n",
    "        cir_noise.phase_flip(1/2, 5)\n",
    "    state_afternoise = cir_noise.run_density_matrix(input_total).numpy()  # numpy.matrix\n",
    "\n",
    "    \n",
    "    # 2. Pass through decoding: Dec_h = Uh @ Dec @ Uh5^dag\n",
    "    # 2.1 Go through Uh5^dag\n",
    "    Uh5 = Uh\n",
    "    for i in range(4):\n",
    "        Uh5 = np.kron(Uh5, Uh)  # get (Uh)^\\otimes 5\n",
    "    # Get state_afterUhdag: 4 mea \\otimes 5 code \\otimes 1 anc\n",
    "    # Apply eye(16) \\otimes Uh5 \\otimes eye(2))\n",
    "    state_afterUhdag = np.kron(np.kron(np.eye(16), Uh5.conj().T), np.eye(2)) @ state_afternoise @ np.kron(np.kron(np.eye(16), Uh5.conj().T), np.eye(2)).conj().T\n",
    "    state_afterUhdag = paddle.to_tensor(state_afterUhdag, dtype = 'complex128')  # change to (paddle.matrix)\n",
    "    # 2.2 Go through decoding: \n",
    "    cir = UAnsatz(10)\n",
    "    stabilizer_meas(cir)\n",
    "    final_total_density = cir.run_density_matrix(state_afterUhdag).numpy()  # (numpy.matrix)\n",
    "    # 2.3 Correct after measure\n",
    "    # There are 16 measure outcomes, for each we do different corrections\n",
    "    # Get the probability and output state for each measure outcomes, store in lists\n",
    "        # prob_meas：32 elements: 16 outcomes (string), and 16 probabilities\n",
    "        # prob_output：16 elements: 16 output states (numpy.matrix)\n",
    "    prob_meas = []\n",
    "    prob_output = []\n",
    "    for i in range(2**4):\n",
    "        basis = TenToTwo(i, n=4)\n",
    "        pr, meas_prob_basis = MeasFiveQ(final_total_density, i)  # measure the first 4 qubits\n",
    "        prob_meas.append(basis+':')\n",
    "        prob_meas.append(pr)\n",
    "        prob_output.append(meas_prob_basis)\n",
    "        \n",
    "    # 3. Do correction for each measure outcome and calculate fidelity for each measurement outcome\n",
    "    fidelityh = 0\n",
    "    for i in range(2**4):\n",
    "        # Get state_aftercori, state_afterVdagi, state_afterUhi\n",
    "        state_aftercori = correct_accoring_tomeas(TenToTwo(i, n=4), prob_output[i])\n",
    "        state_afterVdagi = np.kron(V_Eori.conj().T, np.eye(2)) @ state_aftercori @ np.kron(V_Eori, np.eye(2))\n",
    "        state_afterUhi = np.kron(Uh, np.eye(2)) @ state_afterVdagi @ np.kron(Uh.conj().T, np.eye(2))\n",
    "        # calculate fidelity for each measurement outcome hi\n",
    "        fidelityhi = np.real(bell_state.conj().T @ state_afterUhi @ bell_state)\n",
    "        fidelityh += fidelityhi * np.real(prob_meas[2*i + 1])\n",
    "    fidelityh = fidelityh[0][0]\n",
    "    \n",
    "    return fidelityh\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7c779",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd8c07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840f6cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eb4febf",
   "metadata": {},
   "source": [
    "## Numerical experiment part\n",
    "- iid p-depolarizing noise (every RF state pass through p-depolarizing noise)\n",
    "- erasure noise\n",
    "- completely depolarizing noise (one fifth RF states pass through noise)\n",
    "- completely dephasing noise (one fifth RF states pass through noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4216ddf8",
   "metadata": {},
   "source": [
    "### 1. iid p-depolarizing noise\n",
    "- N_total $\\in$ [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "- p=0.2\n",
    "- Calculate the average entanglement fidelity, with ITR_i_hg = 400 random Ug, store in list f_N_ave_list\n",
    "- Get the worst-case error by : worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "    1. Fittint\n",
    "    2. Get Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaa8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For IID noise: each RF state will has probability p go through a depolarizing, the code space only has one completely depolarizing\n",
    "# Change: For RF space: From_g_get_hath_noise_strong(Ug, N, p)\n",
    "\n",
    "# Get the relation between entanglement fidelity and N_total\n",
    "# ITR_i_hg = 400: Calculate the average entanglement fidelity, with 400 random Ug\n",
    "    # 1. Randomly generate Ug\n",
    "    # 2. Get Uh\n",
    "    # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "    \n",
    "p = 0.2\n",
    "ITR_i_hg = 400\n",
    "\n",
    "# Finally we will get 3 lists: N_total_list, f_N_ave_list, f_N_var_list\n",
    "N_total_list=[40, 70, 100, 150, 200, 300, 400, 500]  # [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "f_N_ave_list = []\n",
    "f_N_var_list = []\n",
    "\n",
    "# For each N_total in N_total_list, calculate fidelity_ave, fidelity_var\n",
    "for N_total in N_total_list:\n",
    "    print('N_total:', N_total)\n",
    "    time_start = time.time() \n",
    "\n",
    "    fidelityh_list =  []  # store fidelityh in each iteration in the list to calculate the average and variance\n",
    "    for i_hg in range(ITR_i_hg):\n",
    "        # 1. Randomly generate Ug\n",
    "        Ug = U2_random_Euler_mod()\n",
    "        # 2. Get measure outcome Uh\n",
    "        Uh = From_g_get_hath_noise_strong(Ug, N_total, p)\n",
    "       # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "        # 3.1 The state after encoding: (Ug)^\\otimes 5 V_E0 Ug^dag\n",
    "        input_total = state_afterencoding(Ug)\n",
    "        # 3.2 The fidelityh with the above Ug, Uh\n",
    "        noise = 1\n",
    "        fidelityh = fidelity_hg(Ug, Uh, input_total, noise)  # depolarizing noise\n",
    "        fidelityh_list.append(fidelityh)\n",
    "    # calculate the average and variance for this N_total\n",
    "    fidelity_ave = np.mean(fidelityh_list)\n",
    "    fidelity_var = np.var(fidelityh_list)\n",
    "    print('fidelity_ave:', fidelity_ave)\n",
    "    print('fidelity_var:', fidelity_var)\n",
    "    f_N_ave_list.append(fidelity_ave)\n",
    "    f_N_var_list.append(fidelity_var)\n",
    "    \n",
    "    time_span = time.time() - time_start \n",
    "    print('time:', time_span)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1526992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot -- for IID noise, p = 0.2\n",
    "\n",
    "# 1. Use the following list -- change to worst-case error\n",
    "#N_total_list\n",
    "err_N_ave_list = [2 * (1-i) for i in f_N_ave_list]  # worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "\n",
    "# 2. Plot original figure\n",
    "plt.figure(1)\n",
    "func1, = plt.plot(N_total_list, err_N_ave_list, \n",
    "                  alpha=0.7, marker='', linestyle=\"-\", color='r')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'iid noise (p = 0.2), with n Bell RF state',\n",
    "    ], loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 3. Fit\n",
    "# The performance is similar as: err_N_ave \\app (coe / N)\n",
    "def func(x, coe):\n",
    "    return coe / x\n",
    "Fitx = N_total_list\n",
    "Fitx = np.array(Fitx)\n",
    "Fity = err_N_ave_list\n",
    "Fity = np.array(Fity)\n",
    " \n",
    "# Least squares method\n",
    "popt, pcov = curve_fit(func, Fitx, Fity)\n",
    "# Get the fitting coefficient\n",
    "coe = popt[0] \n",
    "yvals = func(Fitx, coe)\n",
    "print('coe:', coe)\n",
    "print('pcov:', pcov)\n",
    "# Plot\n",
    "Fitxnew = []\n",
    "Fitynew = []\n",
    "for i in range(N_total_list[0], N_total_list[-1]+1):\n",
    "    Fitxnew.append(i)\n",
    "    Fitynew.append(func(i, coe))\n",
    "plot1 = plt.plot(Fitx, Fity, 's',label='original values')\n",
    "plot2 = plt.plot(Fitxnew, Fitynew, 'r',label='polyfit values')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'iid noise (p = 0.2), with n Bell RF state',\n",
    "    ], loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61178f27",
   "metadata": {},
   "source": [
    "### 2. erasure noise\n",
    "- N $\\in$ [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "- Calculate the average entanglement fidelity, with ITR_i_hg = 400 random Ug, store in list f_N_ave_list\n",
    "- Get the worst-case error by : worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "    1. Fittint\n",
    "    2. Get Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c921757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For erasure noise\n",
    "\n",
    "# Get the relation between entanglement fidelity and N\n",
    "# ITR_i_hg = 400: Calculate the average entanglement fidelity, with 400 random Ug\n",
    "    # 1. Randomly generate Ug\n",
    "    # 2. Get Uh\n",
    "    # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "\n",
    "noise = 1  # Use completely depolarizing noise (same as erasure noise)\n",
    "ITR_i_hg = 400\n",
    "    \n",
    "# Finally we will get 3 lists: N_list, f_N_ave_list, f_N_var_list\n",
    "N_list=[40, 70, 100, 150, 200, 300, 400, 500]  # [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "f_N_ave_list = []\n",
    "f_N_var_list = []\n",
    "\n",
    "# For each N in N_list, calculate fidelity_ave, fidelity_var\n",
    "for N in N_list:\n",
    "    print('N:', N)\n",
    "    time_start = time.time() \n",
    "\n",
    "    fidelityh_list =  []  # store fidelityh in each iteration in the list to calculate the average and variance\n",
    "    for i_hg in range(ITR_i_hg):\n",
    "        # 1. Randomly generate Ug\n",
    "        Ug = U2_random_Euler_mod()\n",
    "        # 2. Get measure outcome Uh\n",
    "        Uh = From_g_get_hath(Ug, N)\n",
    "        # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "        # 3.1 The state after encoding: (Ug)^\\otimes 5 V_E0 Ug^dag\n",
    "        input_total = state_afterencoding(Ug)\n",
    "        # 3.2 The fidelityh with the above Ug, Uh\n",
    "        fidelityh = fidelity_hg(Ug, Uh, input_total, noise)  # depolarizing noise\n",
    "        fidelityh_list.append(fidelityh)\n",
    "    # calculate the average and variance for this N\n",
    "    fidelity_ave = np.mean(fidelityh_list)\n",
    "    fidelity_var = np.var(fidelityh_list)\n",
    "    print('fidelity_ave:', fidelity_ave)\n",
    "    print('fidelity_var:', fidelity_var)\n",
    "    f_N_ave_list.append(fidelity_ave)\n",
    "    f_N_var_list.append(fidelity_var)\n",
    "    \n",
    "    time_span = time.time() - time_start \n",
    "    print('time:', time_span)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57379f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot -- for erasure\n",
    "\n",
    "# 1. Use the following list -- change to worst-case error\n",
    "#N_list\n",
    "err_N_ave_list = [2 * (1-i) for i in f_N_ave_list]  # worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "\n",
    "# 2. Plot original figure\n",
    "plt.figure(1)\n",
    "func1, = plt.plot(N_list, err_N_ave_list, \n",
    "                  alpha=0.7, marker='', linestyle=\"-\", color='r')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'erasure noise, with Bell RF state',\n",
    "    ], loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 3. Fit\n",
    "# The performance is similar as: err_N_ave \\app (coe / N)\n",
    "def func(x, coe):\n",
    "    return coe / x\n",
    "Fitx = N_list\n",
    "Fitx = np.array(Fitx)\n",
    "Fity = err_N_ave_list\n",
    "Fity = np.array(Fity)\n",
    " \n",
    "# Least squares method\n",
    "popt, pcov = curve_fit(func, Fitx, Fity)\n",
    "# Get the fitting coefficient\n",
    "coe = popt[0] \n",
    "yvals = func(Fitx, coe)\n",
    "print('coe:', coe)\n",
    "print('pcov:', pcov)\n",
    "# Plot\n",
    "Fitxnew = []\n",
    "Fitynew = []\n",
    "for i in range(N_list[0], N_list[-1]+1):\n",
    "    Fitxnew.append(i)\n",
    "    Fitynew.append(func(i, coe))\n",
    "plot1 = plt.plot(Fitx, Fity, 's',label='original values')\n",
    "plot2 = plt.plot(Fitxnew, Fitynew, 'r',label='polyfit values')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'erasure noise, with Bell RF state',\n",
    "    ], loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec05493",
   "metadata": {},
   "source": [
    "### 3. completely depolarizing noise\n",
    "- N_total $\\in$ [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "- one fifth RF states pass through noise\n",
    "- Calculate the average entanglement fidelity, with ITR_i_hg = 400 random Ug, store in list f_N_ave_list\n",
    "- Get the worst-case error by : worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "    1. Fittint\n",
    "    2. Get Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eebba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For depolarizing noise, n = 0.2 Ntotal\n",
    "\n",
    "# Get the relation between entanglement fidelity and N_total\n",
    "# ITR_i_hg = 400: Calculate the average entanglement fidelity, with 400 random Ug\n",
    "    # 1. Randomly generate Ug\n",
    "    # 2. Get Uh\n",
    "    # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "    \n",
    "noise = 1  # completely depolarizing noise\n",
    "ITR_i_hg = 400\n",
    "\n",
    "# Finally we will get 3 lists: N_total_list, f_N_ave_list, f_N_var_list\n",
    "N_total_list=[40, 70, 100, 150, 200, 300, 400, 500]  # [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "f_N_ave_list = []\n",
    "f_N_var_list = []\n",
    "\n",
    "# For each N_total in N_total_list, calculate fidelity_ave, fidelity_var\n",
    "for N_total in N_total_list:\n",
    "    print('N_total:', N_total)\n",
    "    n = N_total // 5  # n = 0.2 Ntotal\n",
    "    N = N_total - n\n",
    "    time_start = time.time() \n",
    "\n",
    "    fidelityh_list =  []  # store fidelityh in each iteration in the list to calculate the average and variance\n",
    "    for i_hg in range(ITR_i_hg):\n",
    "        # 1. Randomly generate Ug\n",
    "        Ug = U2_random_Euler_mod()\n",
    "        # 2. Get measure outcome Uh\n",
    "        Uh = From_g_get_hath_noise(Ug, N, n, noise)\n",
    "        # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "        # 3.1 The state after encoding: (Ug)^\\otimes 5 V_E0 Ug^dag\n",
    "        input_total = state_afterencoding(Ug)\n",
    "        # 3.2 The fidelityh with the above Ug, Uh\n",
    "        fidelityh = fidelity_hg(Ug, Uh, input_total, noise)  # depolarizing noise\n",
    "        fidelityh_list.append(fidelityh)\n",
    "    # calculate the average and variance for this N_total\n",
    "    fidelity_ave = np.mean(fidelityh_list)\n",
    "    fidelity_var = np.var(fidelityh_list)\n",
    "    print('fidelity_ave:', fidelity_ave)\n",
    "    print('fidelity_var:', fidelity_var)\n",
    "    f_N_ave_list.append(fidelity_ave)\n",
    "    f_N_var_list.append(fidelity_var)\n",
    "    \n",
    "    time_span = time.time() - time_start \n",
    "    print('time:', time_span)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385e1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot -- for depolarizing noise: one fifth RF go through noise\n",
    "\n",
    "# 1. Use the following list -- change to worst-case error\n",
    "#N_total_list\n",
    "err_N_ave_list = [2 * (1-i) for i in f_N_ave_list]  # worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "\n",
    "# 2. Plot original figure\n",
    "plt.figure(1)\n",
    "func1, = plt.plot(N_total_list, err_N_ave_list, \n",
    "                  alpha=0.7, marker='', linestyle=\"-\", color='r')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'depolarizing noise, with Bell RF state',\n",
    "    ], loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 3. Fit\n",
    "# The performance is similar as: err_N_ave \\app (coe / N)\n",
    "def func(x, coe):\n",
    "    return coe / x\n",
    "Fitx = N_total_list\n",
    "Fitx = np.array(Fitx)\n",
    "Fity = err_N_ave_list\n",
    "Fity = np.array(Fity)\n",
    " \n",
    "# Least squares method\n",
    "popt, pcov = curve_fit(func, Fitx, Fity)\n",
    "# Get the fitting coefficient\n",
    "coe = popt[0] \n",
    "yvals = func(Fitx, coe)\n",
    "print('coe:', coe)\n",
    "print('pcov:', pcov)\n",
    "# Plot\n",
    "Fitxnew = []\n",
    "Fitynew = []\n",
    "for i in range(N_total_list[0], N_total_list[-1]+1):\n",
    "    Fitxnew.append(i)\n",
    "    Fitynew.append(func(i, coe))\n",
    "plot1 = plt.plot(Fitx, Fity, 's',label='original values')\n",
    "plot2 = plt.plot(Fitxnew, Fitynew, 'r',label='polyfit values')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'depolarizing noise, with Bell RF state',\n",
    "    ], loc='best')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180cac2",
   "metadata": {},
   "source": [
    "### 4. completely dephasing noise\n",
    "- N_total $\\in$ [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "- one fifth RF states pass through noise\n",
    "- Calculate the average entanglement fidelity, with ITR_i_hg = 400 random Ug, store in list f_N_ave_list\n",
    "- Get the worst-case error by : worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "    1. Fittint\n",
    "    2. Get Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2113b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dephasing noise, n = 0.2 Ntotal\n",
    "    # noise = 2\n",
    "\n",
    "# Get the relation between entanglement fidelity and N_total\n",
    "# ITR_i_hg = 400: Calculate the average entanglement fidelity, with 400 random Ug\n",
    "    # 1. Randomly generate Ug\n",
    "    # 2. Get Uh\n",
    "    # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "    \n",
    "noise = 2  # completely dephasing noise\n",
    "ITR_i_hg = 400\n",
    "\n",
    "# Finally we will get 3 lists: N_total_list, f_N_ave_list, f_N_var_list\n",
    "N_total_list=[40, 70, 100, 150, 200, 300, 400, 500]  # [40, 70, 100, 150, 200, 300, 400, 500]\n",
    "f_N_ave_list = []\n",
    "f_N_var_list = []\n",
    "\n",
    "# For each N_total in N_total_list, calculate fidelity_ave, fidelity_var\n",
    "for N_total in N_total_list:\n",
    "    print('N_total:', N_total)\n",
    "    n = N_total // 5  # n = 0.2 Ntotal\n",
    "    N = N_total - n\n",
    "    time_start = time.time() \n",
    "\n",
    "    fidelityh_list =  []  # store fidelityh in each iteration in the list to calculate the average and variance\n",
    "    for i_hg in range(ITR_i_hg):\n",
    "        # 1. Randomly generate Ug\n",
    "        Ug = U2_random_Euler_mod()\n",
    "        # 2. Get measure outcome Uh\n",
    "        Uh = From_g_get_hath_noise(Ug, N, n, noise)\n",
    "        # 3. Calculate the entanglement fidelity: 'fidelityh' with this Ug, Uh\n",
    "        # 3.1 The state after encoding: (Ug)^\\otimes 5 V_E0 Ug^dag\n",
    "        input_total = state_afterencoding(Ug)\n",
    "        # 3.2 The fidelityh with the above Ug, Uh\n",
    "        fidelityh = fidelity_hg(Ug, Uh, input_total, noise)  # dephasing noise\n",
    "        fidelityh_list.append(fidelityh)\n",
    "    # calculate the average and variance for this N_total\n",
    "    fidelity_ave = np.mean(fidelityh_list)\n",
    "    fidelity_var = np.var(fidelityh_list)\n",
    "    print('fidelity_ave:', fidelity_ave)\n",
    "    print('fidelity_var:', fidelity_var)\n",
    "    f_N_ave_list.append(fidelity_ave)\n",
    "    f_N_var_list.append(fidelity_var)\n",
    "    \n",
    "    time_span = time.time() - time_start \n",
    "    print('time:', time_span)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027ed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and plot -- for dephasing noise: one fifth RF go through noise\n",
    "\n",
    "# 1. Use the following list -- change to worst-case error\n",
    "#N_total_list\n",
    "err_N_ave_list = [2 * (1-i) for i in f_N_ave_list]  # worst-case error <= 2 * entanglement error = 2 * (1 - entanglement fidelity)\n",
    "\n",
    "# 2. Plot original figure\n",
    "plt.figure(1)\n",
    "func1, = plt.plot(N_total_list, err_N_ave_list, \n",
    "                  alpha=0.7, marker='', linestyle=\"-\", color='r')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'dephasing noise, with Bell RF state',\n",
    "    ], loc='best')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 3. Fit\n",
    "# The performance is similar as: err_N_ave \\app (coe / N)\n",
    "def func(x, coe):\n",
    "    return coe / x\n",
    "Fitx = N_total_list\n",
    "Fitx = np.array(Fitx)\n",
    "Fity = err_N_ave_list\n",
    "Fity = np.array(Fity)\n",
    " \n",
    "# Least squares method\n",
    "popt, pcov = curve_fit(func, Fitx, Fity)\n",
    "# Get the fitting coefficient\n",
    "coe = popt[0] \n",
    "yvals = func(Fitx, coe)\n",
    "print('coe:', coe)\n",
    "print('pcov:', pcov)\n",
    "# Plot\n",
    "Fitxnew = []\n",
    "Fitynew = []\n",
    "for i in range(N_total_list[0], N_total_list[-1]+1):\n",
    "    Fitxnew.append(i)\n",
    "    Fitynew.append(func(i, coe))\n",
    "plot1 = plt.plot(Fitx, Fity, 's',label='original values')\n",
    "plot2 = plt.plot(Fitxnew, Fitynew, 'r',label='polyfit values')\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('worst-case error')\n",
    "plt.legend(handles=[\n",
    "    func1,\n",
    "],\n",
    "    labels=[\n",
    "        'dephasing noise, with Bell RF state',\n",
    "    ], loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14c7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
